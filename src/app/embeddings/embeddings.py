"""
ì„ë² ë”© ìƒì„± ëª¨ë“ˆ
ê²€ìƒ‰ ì •í™•ë„ì™€ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ì„ë² ë”© ì‹œìŠ¤í…œ
"""
from typing import List, Dict, Any
import numpy as np
from sentence_transformers import SentenceTransformer
import torch
from pathlib import Path

class EmbeddingModel:
    """ì„ë² ë”© ëª¨ë¸ ë˜í¼ í´ë˜ìŠ¤"""
    
    def __init__(self, model_name: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"):
        """
        ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            model_name: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ ì´ë¦„
        """
        self.model_name = model_name
        self.model = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.load_model()
        
    def load_model(self):
        """ëª¨ë¸ ë¡œë”©"""
        try:
            print(f"ğŸ¤– ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘: {self.model_name}")
            self.model = SentenceTransformer(self.model_name)
            self.model.to(self.device)
            print(f"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ (ë””ë°”ì´ìŠ¤: {self.device})")
        except Exception as e:
            raise RuntimeError(f"ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        
    def encode(self, texts: List[str], batch_size: int = 32, show_progress: bool = True) -> np.ndarray:
        """
        í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        
        Args:
            texts: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            batch_size: ë°°ì¹˜ í¬ê¸°
            show_progress: ì§„í–‰ë¥  í‘œì‹œ ì—¬ë¶€
            
        Returns:
            ì„ë² ë”© ë²¡í„° ë°°ì—´
        """
        if not texts:
            return np.array([])
        
        try:
            # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
            embeddings = self.model.encode(
                texts,
                batch_size=batch_size,
                show_progress_bar=show_progress,
                convert_to_numpy=True,
                device=self.device
            )
            
            return embeddings
            
        except Exception as e:
            raise RuntimeError(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")
        
    def encode_single(self, text: str) -> np.ndarray:
        """
        ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        
        Args:
            text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
            
        Returns:
            ì„ë² ë”© ë²¡í„°
        """
        if not text:
            return np.array([])
        
        try:
            embedding = self.model.encode(
                [text],
                convert_to_numpy=True,
                device=self.device
            )
            
            return embedding[0]  # ë‹¨ì¼ ë²¡í„° ë°˜í™˜
            
        except Exception as e:
            raise RuntimeError(f"ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def get_embedding_dimension(self) -> int:
        """
        ì„ë² ë”© ì°¨ì› ìˆ˜ ë°˜í™˜
        
        Returns:
            ì„ë² ë”© ì°¨ì› ìˆ˜
        """
        if self.model is None:
            return 0
        
        # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ë¡œ ì°¨ì› í™•ì¸
        test_embedding = self.encode_single("test")
        return len(test_embedding)
    
    def get_model_info(self) -> Dict[str, Any]:
        """
        ëª¨ë¸ ì •ë³´ ë°˜í™˜
        
        Returns:
            ëª¨ë¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        return {
            "model_name": self.model_name,
            "device": self.device,
            "is_loaded": self.model is not None,
            "embedding_dimension": self.get_embedding_dimension()
        }

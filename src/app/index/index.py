"""
ë²¡í„° ì¸ë±ìŠ¤ ê´€ë¦¬ ëª¨ë“ˆ
ê²€ìƒ‰ ì •í™•ë„ì™€ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ì¸ë±ì‹± ì‹œìŠ¤í…œ
"""
from typing import List, Dict, Any, Optional, Tuple
import numpy as np
import chromadb
from chromadb.config import Settings as ChromaSettings
import os
import json
from pathlib import Path

from app.embeddings.embeddings import EmbeddingModel
from app.data.preprocess import load_and_process_korquad

class VectorIndex:
    """ë²¡í„° ì¸ë±ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 index_dir: str = "./vector_index",
                 collection_name: str = "korquad_docs",
                 model_name: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                 score_threshold: float = 0.6):
        """
        ë²¡í„° ì¸ë±ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            index_dir: ì¸ë±ìŠ¤ ì €ì¥ ë””ë ‰í† ë¦¬
            collection_name: ChromaDB ì»¬ë ‰ì…˜ ì´ë¦„
            model_name: ì„ë² ë”© ëª¨ë¸ ì´ë¦„
            score_threshold: ìœ ì‚¬ë„ ì ìˆ˜ ì„ê³„ê°’
        """
        self.index_dir = index_dir
        self.collection_name = collection_name
        self.score_threshold = score_threshold
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(index_dir, exist_ok=True)
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.embedding_model = EmbeddingModel(model_name)
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = None
        self.collection = None
        self._initialize_chroma()
        
    def _initialize_chroma(self):
        """ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            self.client = chromadb.PersistentClient(
                path=self.index_dir,
                settings=ChromaSettings(
                    anonymized_telemetry=False,
                    allow_reset=True
                )
            )
            
            # ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
            try:
                self.collection = self.client.get_collection(name=self.collection_name)
                print(f"âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ ë¡œë“œ: {self.collection_name}")
            except:
                self.collection = self.client.create_collection(
                    name=self.collection_name,
                    metadata={"description": "KorQuAD ë¬¸ì„œ ì»¬ë ‰ì…˜"}
                )
                print(f"âœ… ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {self.collection_name}")
                
        except Exception as e:
            raise RuntimeError(f"ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    
    def build_index(self, data_path: str, chunk_size: int = 500, overlap: int = 50) -> Dict[str, Any]:
        """
        ìµœì´ˆ 1íšŒ ì „ì²˜ë¦¬í•œ KorQuAD ë°ì´í„°ë¥¼ ì¸ë±ì‹±
        
        Args:
            data_path: KorQuAD ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            chunk_size: ì²­í¬ í¬ê¸°
            overlap: ê²¹ì¹˜ëŠ” ë¶€ë¶„ í¬ê¸°
            
        Returns:
            ì¸ë±ì‹± ê²°ê³¼ ì •ë³´
        """
        print("ğŸš€ ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œì‘...")
        
        try:
            # 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
            print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì¤‘...")
            documents, metadatas, doc_ids = load_and_process_korquad(
                data_path, chunk_size, overlap
            )
            
            if not documents:
                raise ValueError("ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            print(f"âœ… {len(documents)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ")
            
            # 2. ì„ë² ë”© ìƒì„±
            print("ğŸ§  ì„ë² ë”© ìƒì„± ì¤‘...")
            embeddings = self.embedding_model.encode(documents, batch_size=32)
            print(f"âœ… {embeddings.shape[0]}ê°œ ì„ë² ë”© ìƒì„± ì™„ë£Œ")
            
            # 3. ChromaDBì— ì €ì¥
            print("ğŸ’¾ ë²¡í„° ì¸ë±ìŠ¤ ì €ì¥ ì¤‘...")
            self.collection.add(
                documents=documents,
                metadatas=metadatas,
                ids=doc_ids,
                embeddings=embeddings.tolist()
            )
            
            # 4. ì¸ë±ìŠ¤ ë©”íƒ€ë°ì´í„° ì €ì¥
            index_metadata = {
                "total_documents": len(documents),
                "embedding_dimension": embeddings.shape[1],
                "model_name": self.embedding_model.model_name,
                "chunk_size": chunk_size,
                "overlap": overlap,
                "score_threshold": self.score_threshold,
                "data_path": data_path
            }
            
            self._save_index_metadata(index_metadata)
            
            print("âœ… ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ!")
            return index_metadata
            
        except Exception as e:
            raise RuntimeError(f"ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨: {str(e)}")
    
    def persist(self) -> bool:
        """
        ë¡œì»¬ ë””ë ‰í† ë¦¬ì— ì €ì¥ (ì¬ì‹œì‘í•´ë„ ìœ ì§€)
        
        Returns:
            ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ChromaDBëŠ” ìë™ìœ¼ë¡œ ì˜êµ¬ ì €ì¥ë˜ë¯€ë¡œ ë©”íƒ€ë°ì´í„°ë§Œ ì €ì¥
            metadata_path = os.path.join(self.index_dir, "index_metadata.json")
            
            if os.path.exists(metadata_path):
                print(f"âœ… ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {self.index_dir}")
                return True
            else:
                print("âš ï¸ ì €ì¥í•  ì¸ë±ìŠ¤ ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
                
        except Exception as e:
            print(f"âŒ ì¸ë±ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def load_index(self) -> bool:
        """
        ì„œë²„ ì¬ì‹œì‘ ì‹œ ê¸°ì¡´ ì¸ë±ìŠ¤ë¥¼ ë‹¤ì‹œ ë¡œë“œ
        
        Returns:
            ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ChromaDB ì»¬ë ‰ì…˜ ë¡œë“œ í™•ì¸
            if self.collection is None:
                return False
            
            # ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
            count = self.collection.count()
            if count == 0:
                print("âš ï¸ ë¹ˆ ì»¬ë ‰ì…˜ì…ë‹ˆë‹¤.")
                return False
            
            # ë©”íƒ€ë°ì´í„° ë¡œë“œ
            metadata = self._load_index_metadata()
            if metadata:
                print(f"âœ… ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {count}ê°œ ë¬¸ì„œ")
                print(f"   - ëª¨ë¸: {metadata.get('model_name', 'N/A')}")
                print(f"   - ì°¨ì›: {metadata.get('embedding_dimension', 'N/A')}")
                print(f"   - ì„ê³„ê°’: {metadata.get('score_threshold', 'N/A')}")
                return True
            else:
                print("âš ï¸ ì¸ë±ìŠ¤ ë©”íƒ€ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
                
        except Exception as e:
            print(f"âŒ ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def search(self, query: str, top_k: int = 5, score_threshold: Optional[float] = None) -> List[Dict[str, Any]]:
        """
        ì§ˆë¬¸ ì…ë ¥ ì‹œ top_k ë¬¸ì„œ ë°˜í™˜ (ì¶œì²˜ ì •ë³´ì™€ í•¨ê»˜)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            score_threshold: ìœ ì‚¬ë„ ì ìˆ˜ ì„ê³„ê°’ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if not query:
            return []
        
        try:
            # ì„ê³„ê°’ ì„¤ì •
            threshold = score_threshold if score_threshold is not None else self.score_threshold
            
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self.embedding_model.encode_single(query)
            
            # ChromaDB ê²€ìƒ‰
            results = self.collection.query(
                query_embeddings=[query_embedding.tolist()],
                n_results=top_k,
                include=["documents", "metadatas", "distances"]
            )
            
            # ê²°ê³¼ í¬ë§·íŒ… ë° í•„í„°ë§
            formatted_results = []
            if results['documents'] and results['documents'][0]:
                for i, (doc, metadata, distance) in enumerate(zip(
                    results['documents'][0],
                    results['metadatas'][0],
                    results['distances'][0]
                )):
                    # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ë³€í™˜ (0-1 ë²”ìœ„)
                    similarity_score = 1 - distance
                    
                    # ì„ê³„ê°’ í•„í„°ë§
                    if similarity_score < threshold:
                        continue
                    
                    # ì¶œì²˜ ì •ë³´ í¬í•¨
                    formatted_results.append({
                        "id": metadata.get("id", f"result_{i}"),
                        "title": metadata.get("title", "ì œëª© ì—†ìŒ"),
                        "content": doc,
                        "score": round(similarity_score, 4),
                        "snippet": doc[:200] + "..." if len(doc) > 200 else doc,
                        "metadata": {
                            "original_id": metadata.get("original_id", ""),
                            "chunk_index": metadata.get("chunk_index", 0),
                            "start": metadata.get("start", 0),
                            "end": metadata.get("end", 0),
                            "sentence_count": metadata.get("sentence_count", 0),
                            "source": metadata.get("source", "korquad")
                        }
                    })
            
            return formatted_results
            
        except Exception as e:
            raise RuntimeError(f"ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
    
    def _save_index_metadata(self, metadata: Dict[str, Any]):
        """ì¸ë±ìŠ¤ ë©”íƒ€ë°ì´í„° ì €ì¥"""
        try:
            metadata_path = os.path.join(self.index_dir, "index_metadata.json")
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def _load_index_metadata(self) -> Optional[Dict[str, Any]]:
        """ì¸ë±ìŠ¤ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        try:
            metadata_path = os.path.join(self.index_dir, "index_metadata.json")
            if os.path.exists(metadata_path):
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return None
        except Exception as e:
            print(f"âš ï¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def get_index_info(self) -> Dict[str, Any]:
        """
        ì¸ë±ìŠ¤ ì •ë³´ ì¡°íšŒ
        
        Returns:
            ì¸ë±ìŠ¤ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        try:
            count = self.collection.count() if self.collection else 0
            metadata = self._load_index_metadata()
            
            return {
                "collection_name": self.collection_name,
                "total_documents": count,
                "index_dir": self.index_dir,
                "score_threshold": self.score_threshold,
                "embedding_model": self.embedding_model.get_model_info(),
                "metadata": metadata
            }
        except Exception as e:
            return {"error": f"ì¸ë±ìŠ¤ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"}
    
    def update_score_threshold(self, new_threshold: float):
        """
        ìœ ì‚¬ë„ ì ìˆ˜ ì„ê³„ê°’ ì—…ë°ì´íŠ¸
        
        Args:
            new_threshold: ìƒˆë¡œìš´ ì„ê³„ê°’
        """
        if 0.0 <= new_threshold <= 1.0:
            self.score_threshold = new_threshold
            print(f"âœ… ì„ê³„ê°’ ì—…ë°ì´íŠ¸: {new_threshold}")
        else:
            raise ValueError("ì„ê³„ê°’ì€ 0.0ê³¼ 1.0 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")
    
    def clear_index(self):
        """ì¸ë±ìŠ¤ ì´ˆê¸°í™”"""
        try:
            if self.collection:
                # ì»¬ë ‰ì…˜ ì‚­ì œ
                self.client.delete_collection(self.collection_name)
                
                # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
                self.collection = self.client.create_collection(
                    name=self.collection_name,
                    metadata={"description": "KorQuAD ë¬¸ì„œ ì»¬ë ‰ì…˜"}
                )
                
                # ë©”íƒ€ë°ì´í„° íŒŒì¼ ì‚­ì œ
                metadata_path = os.path.join(self.index_dir, "index_metadata.json")
                if os.path.exists(metadata_path):
                    os.remove(metadata_path)
                
                print("âœ… ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            raise RuntimeError(f"ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
